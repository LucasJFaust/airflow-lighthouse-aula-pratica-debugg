# airflow-lighthouse-aula-pratica-debugg
# üõ†Ô∏è Astro CLI + Airflow: Debugging e Solu√ß√£o de Problemas em Orquestra√ß√£o

## 1. Vis√£o Geral

Bem-vindos ao reposit√≥rio de suporte √† aula pr√°tica de "Lidando com problemas de Orquestra√ß√£o | Airflow, debugging, logs"! Este projeto foi cuidadosamente elaborado para simular **cinco cen√°rios comuns de falhas** em pipelines de dados orquestrados pelo Apache Airflow.

Aqui, voc√™ ter√° a oportunidade de aplicar os conceitos te√≥ricos aprendidos na aula, utilizando o **Astro CLI** para agilizar o desenvolvimento e depura√ß√£o local, e a **Airflow UI** para monitoramento e an√°lise detalhada. Nosso objetivo √© transformar voc√™ em um verdadeiro "detetive" de dados, capaz de navegar pela complexidade e garantir a resili√™ncia dos seus pipelines, mesmo **sem depender exclusivamente da interface gr√°fica**.

## 2. Pr√©-requisitos - Preparando seu Ambiente

Para que voc√™ possa executar este projeto e aproveitar a experi√™ncia pr√°tica, certifique-se de ter os seguintes softwares e ferramentas instalados e configurados em sua m√°quina. **√â crucial seguir estas etapas para garantir que o Astro CLI funcione corretamente.**

1.  **[VS Code](https://code.visualstudio.com/):** Nosso ambiente de desenvolvimento integrado (IDE) preferido. Ele oferece excelentes recursos para Python e Docker. Instale-o se ainda n√£o tiver.
2.  **[Docker Desktop](https://www.docker.com/products/docker-desktop/):** O Astro CLI utiliza Docker para criar e gerenciar seu ambiente Airflow local. **Certifique-se de que o Docker Desktop esteja em execu√ß√£o** antes de iniciar o ambiente Astro. Fa√ßa o download e a instala√ß√£o para o seu sistema operacional.
3.  **[Astro CLI](https://docs.astronomer.io/astro/cli/install-cli):** A ferramenta de linha de comando essencial para interagir com o Airflow, tanto localmente quanto com o Astronomer Cloud.

    ### Instala√ß√£o do Astro CLI (Escolha uma op√ß√£o):

    *   **macOS (Homebrew):**
        ```bash
        brew install astro
        ```
    *   **Linux (apt):**
        ```bash
        curl -sL 'https://raw.githubusercontent.com/astronomer/astro-cli/main/install.sh' | sudo bash -s -- -b /usr/local/bin
        ```
    *   **Windows (Chocolatey ou WSL):** A forma mais recomendada para Windows √© usar o [WSL (Windows Subsystem for Linux)](https://learn.microsoft.com/pt-br/windows/wsl/) e instalar o Astro CLI dentro dele, seguindo as instru√ß√µes do Linux. Alternativamente, voc√™ pode usar o Chocolatey.
        ```powershell
        # No PowerShell (como Administrador)
        choco install astro-cli
        ```
        (Verifique a documenta√ß√£o oficial para a instala√ß√£o mais atualizada para Windows). 

    ### Verifica√ß√£o da Instala√ß√£o do Astro CLI:

    Ap√≥s a instala√ß√£o, abra seu terminal (ou o terminal integrado do VS Code) e execute:
    ```bash
    astro version
    ```
    Voc√™ dever√° ver a vers√£o do Astro CLI instalada. Se voc√™ receber um erro, revise as etapas de instala√ß√£o.

## 3. Configura√ß√£o e Inicializa√ß√£o do Ambiente

Siga estes passos para configurar e iniciar seu ambiente Airflow local. **Leia com aten√ß√£o para entender o fluxo de trabalho local com o Astro CLI.**

1.  **Clone o Reposit√≥rio e crie um arquivo de requirements.txt:**
    Abra seu terminal e execute:
    ```bash
    git clone https://github.com/LucasJFaust/airflow-lighthouse-aula-pratica-debugg # Substitua pela URL real do seu reposit√≥rio
    cd seu-repositorio-de-aula # Navegue at√© a pasta do projeto
    ```
     **Verifique e prepare o `requirements.txt`:**
    O Astro CLI utiliza o arquivo `requirements.txt` (localizado na raiz do seu projeto) para instalar as depend√™ncias Python necess√°rias dentro do ambiente Airflow. **Certifique-se de que este arquivo existe e contenha todas as bibliotecas que suas DAGs ir√£o utilizar (como `requests`,  etc.) ANTES de iniciar o ambiente.**

        **‚ö†Ô∏è IMPORTANTE:** **N√ÉO inclua `apache-airflow` (ou qualquer outra varia√ß√£o como `apache-airflow-providers-*`) diretamente no seu `requirements.txt`.** A vers√£o do Airflow √© definida pela imagem de runtime base utilizada pelo Astro CLI. Se voc√™ precisar de uma vers√£o espec√≠fica do Airflow, ajuste a vers√£o no `Dockerfile` dentro da pasta `.astro/`.

    Exemplo de `requirements.txt` para este projeto:
    ```
    requests
    ```
    *   **Importante:** Se voc√™ modificar o `requirements.txt` ap√≥s o `astro dev start` inicial, ser√° necess√°rio executar `astro dev restart` (ou `astro dev kill` e `astro dev start`) para que as novas depend√™ncias sejam instaladas nos cont√™ineres do Airflow.
    No terminal execute:
    ```bash
    touch requirements.txt
    ```


2.  **Inicie o Ambiente Airflow Local com Astro CLI:**
     Este comando cria a estrutura de projeto que o Astro CLI espera (`.astro/` folder, `Dockerfile` e `packages.txt`).
    ```bash
    astro dev init
    ```
    *   Se for perguntado sobre sobrescrever arquivos como `Dockerfile` ou `packages.txt`, pode aceitar as op√ß√µes padr√£o ou pular se j√° tiverem customiza√ß√µes que voc√™ queira manter (neste caso, para a aula, os padr√µes s√£o suficientes).
    *   **Opcional:** Se voc√™ tem customiza√ß√µes em um `Dockerfile` ou `packages.txt` que n√£o foram criados pelo `astro dev init`, voc√™ pode mov√™-los para dentro da pasta `.astro/` ap√≥s a inicializa√ß√£o. Para este laborat√≥rio, o `astro dev init` j√° cria o b√°sico necess√°rio.
    Dentro da pasta do projeto (`seu-repositorio-de-aula`), execute o comando para iniciar o ambiente Airflow local. **Este √© o comando chave para come√ßar a trabalhar. Verifique que est√° executando ele no diret√≥rio correto.**
    ```bash
    astro dev start
    ```
    *   Este comando ir√°:
        *   Ler o arquivo `requirements.txt` e instalar as depend√™ncias Python no ambiente Airflow.
        *   Baixar as imagens Docker necess√°rias (Airflow Scheduler, Webserver, PostgreSQL, Redis).
        *   Construir os cont√™ineres e inici√°-los, configurando as redes e volumes necess√°rios.
        *   Sincronizar seus arquivos de DAGs (na pasta `dags/`) com o cont√™iner do Airflow.
    *   Este processo pode levar **v√°rios minutos na primeira vez** (especialmente o download das imagens). Tenha paci√™ncia.

    ### Solu√ß√£o de Problemas Comuns `astro dev start`:

    *   **Docker Desktop n√£o iniciado:** Verifique se o Docker Desktop est√° rodando. O `astro dev start` *depende* dele.
    *   **Porta 8080 em uso:** Se voc√™ tiver outro servi√ßo usando a porta `8080`, o Astro CLI pode falhar. Voc√™ pode parar o outro servi√ßo ou, para ambientes mais avan√ßados, configurar o `docker-compose.yaml` gerado pelo Astro CLI em `.astro/` para usar outra porta.
    *   **Erros de `requirements.txt`:** Se houver erros na instala√ß√£o de pacotes Python, verifique a sintaxe do seu `requirements.txt`.

3.  **Acesse a UI do Airflow:**
    Ap√≥s o `astro dev start` concluir, o terminal exibir√° a URL da interface do usu√°rio do Airflow. Geralmente, √©:
    [http://localhost:8080/](http://localhost:8080/) 
    Abra essa URL em seu navegador. As credenciais padr√£o s√£o `admin`/`admin`.

## 4. Estrutura do Projeto

Entender a estrutura do projeto √© crucial para a navega√ß√£o e o debugging:
seu-repositorio-de-aula/
```
‚îú‚îÄ‚îÄ dags/ # Cont√©m os arquivos Python das DAGs
‚îÇ ‚îú‚îÄ‚îÄ problem_config_and_logic_dag.py # Problema 1: Vari√°vel e L√≥gica
‚îÇ ‚îú‚îÄ‚îÄ problem_stuck_sensor_dag.py # Problema 2: Sensor que trava
‚îÇ ‚îú‚îÄ‚îÄ problem_dag_parsing_error.py # Problema 3: Erro de Parsing/Sintaxe (DAG n√£o aparece!)
‚îÇ ‚îú‚îÄ‚îÄ problem_resource_intensive_dag.py # Problema 4: Consumo de Recursos (OOMKilled/Lento)
‚îÇ ‚îî‚îÄ‚îÄ problem_external_connection_dag.py # Problema 5: Erro de Conex√£o Externa
‚îú‚îÄ‚îÄ data/ # Cont√©m arquivos de dados de exemplo utilizados pelas DAGs
‚îÇ ‚îî‚îÄ‚îÄ initial_data.txt
‚îú‚îÄ‚îÄ .astro/ # Diret√≥rio oculto gerado pelo Astro CLI com configura√ß√µes
‚îú‚îÄ‚îÄ .env # Arquivo de vari√°veis de ambiente (se usado)
‚îú‚îÄ‚îÄ requirements.txt # Lista de pacotes Python para o ambiente Airflow
‚îú‚îÄ‚îÄ docker-compose.yaml # Arquivo Docker Compose gerado pelo Astro CLI ‚îî‚îÄ‚îÄ README.md # Este arquivo!
```

## 5. O Case T√©cnico - Cen√°rios de Problemas (e como diagnostic√°-los!)

Este projeto cont√©m **cinco DAGs intencionalmente problem√°ticas**, cada uma demonstrando um tipo diferente de falha comum em pipelines de dados Airflow, conforme discutido no **Slide 13: Fontes de Problemas**.

Para cada problema, voc√™ dever√° usar as ferramentas visuais da Airflow UI e os poderosos comandos do Astro CLI para identificar e diagnosticar a causa raiz.

### Guia Geral de Debugging e An√°lise de Logs (Sua Caixa Preta!)

Antes de mergulhar nos problemas espec√≠ficos, familiarize-se com a abordagem geral de depura√ß√£o, que integra os conceitos dos **Slides 05, 06, 11 e 12** da apresenta√ß√£o:

1.  **Identifica√ß√£o Visual (Airflow UI - Grid View / Graph View):**
    *   V√° para a `Grid View` do DAG problem√°tico. Observe o status geral.
    *   **Pergunte-se (Slide 05 - Grid View):** "Qual tarefa est√° em vermelho (falha) ou em um estado inesperado (`up_for_retry`, `running` indefinidamente)? Quais s√£o as cores das outras tarefas? H√° algum padr√£o de falha?"
    *   Navegue para a `Graph View` do DAG.
    *   **Pergunte-se (Slide 06 - Graph View):** "Qual √© a sequ√™ncia de execu√ß√£o? Qual tarefa falhou e quais tarefas s√£o `downstream` dela? Elas foram `skipped`? Isso faz sentido com as depend√™ncias?"

2.  **An√°lise de Logs (Airflow UI - Task Instance Logs / Astro CLI Logs):**
    *   **Primeira Leitura (UI):** Na `Grid View` ou `Graph View`, clique na tarefa falha (ou na que est√° travada) e selecione "View Log" ou "Logs".
    *   **Pergunte-se (Slide 11 - Anatomia dos Logs):**
        *   "Qual √© o `Timestamp` do erro? Houve algum evento anterior relevante?"
        *   "Qual √© o `Level` da mensagem? Estou vendo `ERROR` ou `CRITICAL`?"
        *   "Qual a `Message` do erro? H√° alguma mensagem `print()` minha que pode dar uma pista?"
        *   "H√° um `StackTrace`? Se sim, lembre-se: **leia de baixo para cima**! Qual o `Exception Type` e onde est√° o n√∫mero da linha no c√≥digo da minha DAG?"
    *   **Leitura Detalhada (Astro CLI) - SEMPRE QUE POSS√çVEL, USE ESTES COMANDOS!**
        Abra um novo terminal no VS Code (sem parar o `astro dev start`).
        *   Para ver logs de uma tarefa espec√≠fica diretamente no terminal (mais r√°pido e f√°cil para copiar):
            ```bash
            astro dev logs --dag-id <dag_id> --task-id <task_id> --follow
            # Exemplo: astro dev logs --dag-id problem_config_and_logic_dag --task-id process_data_with_config_and_logic_error --follow
            ```
        *   Para seguir os logs de todos os componentes do Airflow (√∫til para `Scheduler` e `Webserver` logs):
            ```bash
            astro dev logs --follow
            ```
        *   **Pergunte-se (Slide 12 - Estrat√©gias de Busca):** "Com quais `Keywords` posso procurar? `ERROR`, `Exception`, `Failed`, `Traceback`? Posso filtrar por `task_id` ou `Timestamp`?"

3.  **Diagn√≥stico e Racioc√≠nio L√≥gico (Aplicando o Slide 13 - Fontes de Problemas):**
    *   Com base nos logs, qual √© a **causa raiz** do problema?
    *   **Pergunte-se:** "Qual categoria de problema (do Slide 13) se encaixa melhor aqui? Isso me ajuda a pensar na solu√ß√£o?"
    *   **Pergunte-se:** "Como eu poderia simular esse erro rapidamente localmente para testar uma poss√≠vel corre√ß√£o, antes de mudar o DAG completo, **sem precisar da UI do Airflow**?" (Pense nos comandos `astro dev run airflow tasks test` ou `astro dev run airflow dags parse` - **Slide 10**).

---

### Detalhes de Cada Problema e Passos para Reprodu√ß√£o

#### Problema 1: Vari√°vel de Configura√ß√£o Ausente e Erro de L√≥gica (`problem_config_and_logic_dag`)

*   **Descri√ß√£o:** Este DAG falha porque espera uma `Airflow Variable` (`processing_chunk_size`) que n√£o est√° definida na UI do Airflow. Al√©m disso, se a vari√°vel fosse definida, h√° um erro l√≥gico que pode ocorrer em um caso de borda.
*   **Categorias de Problema (Slide 13):** Permiss√µes/Vari√°veis (principal), L√≥gica da Task (secund√°rio).
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_config_and_logic_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Observe a falha na `Grid View`.
*   **Diagn√≥stico e Pistas:**
    *   A tarefa `process_data_with_config_and_logic_error` falhar√°.
    *   Os logs (UI ou `astro dev logs`) mostrar√£o um `KeyError` ou `ValueError` relacionado √† `Variable.get("processing_chunk_size")`.
*   **Solu√ß√£o:**
    1.  **Corrija a Vari√°vel:** Na Airflow UI, v√° em `Admin` -> `Variables`. Crie uma nova vari√°vel com **Key:** `processing_chunk_size` e **Value:** `10` (ou qualquer n√∫mero inteiro).
    2.  Dispare o DAG novamente. Observe que ele passar√° pela primeira falha.
    3.  *(Opcional/Discuss√£o em aula):* Se o `IndexError` surgir (dependendo da manipula√ß√£o de `initial_data.txt`), mostre como o `astro dev run airflow tasks test` para a fun√ß√£o `_process_data_with_config_and_logic_error` poderia ter ajudado a isolar o erro de l√≥gica.
    4.  Para corre√ß√£o do problema de l√≥gica, solicite acesso ao guia de de solu√ß√µes mais completo que elaborei.

#### Problema 2: Sensor Travado (`problem_stuck_sensor_dag`)

*   **Descri√ß√£o:** Este DAG tem um `FileSensor` que aguarda a cria√ß√£o de um arquivo espec√≠fico (`/tmp/data_notification_file.txt`). No entanto, a tarefa anterior que deveria criar este arquivo (`_generate_data_but_fail_to_create_notification_file`) *intencionalmente n√£o o faz*, fazendo com que o sensor fique travado at√© atingir seu `timeout`.
*   **Categorias de Problema (Slide 13):** L√≥gica da Task (a tarefa anterior falha em sua l√≥gica de notifica√ß√£o), Conex√£o Externa (do ponto de vista do sensor, o evento externo n√£o ocorreu).
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_stuck_sensor_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Observe que a tarefa `wait_for_data_notification` permanecer√° em estado `running` (ou `up_for_retry`) por um tempo, eventualmente falhando por `timeout`.
*   **Diagn√≥stico e Pistas:**
    *   Os logs da tarefa `wait_for_data_notification` mostrar√£o repeti√ß√µes de "Poking for file..." e, eventualmente, um `AirflowSensorTimeout`.
    *   Os logs da tarefa `generate_data_but_fail_to_create_notification_file` (a `upstream`) s√£o cruciais: eles indicar√£o que o arquivo *n√£o* foi criado intencionalmente. Use `astro dev logs` para v√™-los em detalhe.
*   **Solu√ß√£o:**
    1.  **Edite o DAG:** No VS Code, abra `dags/problem_stuck_sensor_dag.py`.
    2.  Na fun√ß√£o `_generate_data_but_fail_to_create_notification_file`, **descomente as linhas** que criam o arquivo `/tmp/data_notification_file.txt`.
    3.  Salve o arquivo. O Airflow recarregar√° a DAG.
    4.  Dispare o DAG novamente na UI. O sensor dever√° passar rapidamente.

#### Problema 3: Erro de Parsing/Sintaxe (`problem_dag_parsing_error`)

*   **Descri√ß√£o:** Este arquivo de DAG (`problem_dag_parsing_error.py`) cont√©m um erro de sintaxe Python intencional. Isso impedir√° que o `Airflow Scheduler` consiga carreg√°-lo, resultando na DAG **n√£o aparecendo na UI** ou gerando um `Dag Import Error` no log do Scheduler.
*   **Categorias de Problema (Slide 13):** Parsing da DAG.
*   **Passos para Reproduzir:**
    1.  **Inicialmente, esta DAG N√ÉO APARECER√Å na UI do Airflow.** Este √© o primeiro sinal.
    2.  Se voc√™ tentar corrigir, mas o erro persistir, o Scheduler pode reclamar.
*   **Diagn√≥stico e Pistas (SEM A UI!):**
    *   **Primeira pista:** A DAG simplesmente n√£o est√° na lista de DAGs da Airflow UI.
    *   **Astro CLI para diagnosticar parsing (Slide 10):**
        Abra um terminal e execute:
        ```bash
        astro dev run airflow dags parse /usr/local/airflow/dags/3-problem_dag_parsing_error.py
        ```
        *Este comando ir√° simular o processo de parsing do Airflow e reportar o erro de sintaxe diretamente no seu terminal, indicando a linha exata!*
    *   Verifique os logs do Scheduler via `astro dev logs --follow`. Voc√™ ver√° mensagens de `DagFileProcessor` falhando ao carregar o arquivo.
*   **Solu√ß√£o:**
    1.  **Edite o DAG:** No VS Code, abra `dags/problem_dag_parsing_error.py`.
    2.  **Corrija o erro de sintaxe:** Por exemplo, adicione o par√™ntese `)` que falta na linha do `print()`.
    3.  Salve o arquivo. O Scheduler detectar√° a mudan√ßa e tentar√° recarregar.
    4.  Verifique a Airflow UI; a DAG `problem_dag_parsing_error` agora dever√° aparecer.

#### Problema 4: Uso Intenso de Recursos (`problem_resource_intensive_dag`)

*   **Descri√ß√£o:** A tarefa `consume_memory_and_cpu_task` tenta alocar uma grande quantidade de mem√≥ria e/ou executa um loop pesado. Dependendo da configura√ß√£o de recursos do seu ambiente Docker, isso pode levar a:
    *   Uma falha `OOMKilled` (Out Of Memory Killed), onde o sistema operacional encerra a tarefa.
    *   Uma execu√ß√£o extremamente lenta que eventualmente atinge um timeout do Airflow, ou apenas demora muito.
*   **Categorias de Problema (Slide 13):** Recursos.
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_resource_intensive_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Observe o status da tarefa. Ela pode ficar `running` por muito tempo e, em seguida, falhar.
*   **Diagn√≥stico e Pistas:**
    *   **Logs da tarefa (UI ou `astro dev logs`):** Procure por mensagens como `Killed`, `SIGKILL`, ou informa√ß√µes sobre uso de mem√≥ria excessivo. Muitas vezes, n√£o h√° um `Traceback` Python claro, apenas uma indica√ß√£o de que o processo foi encerrado pelo sistema.
    *   **Observa√ß√£o de recursos do Docker Desktop:** Monitore o uso de mem√≥ria/CPU do Docker Desktop enquanto a tarefa roda.
*   **Solu√ß√£o (Discuss√£o):**
    *   Este problema n√£o tem uma "corre√ß√£o de c√≥digo" simples, mas sim uma discuss√£o sobre:
        *   **Otimiza√ß√£o do C√≥digo:** A tarefa est√° processando dados de forma ineficiente? H√° maneiras de reduzir o consumo de mem√≥ria (ex: processar em chunks)?
        *   **Configura√ß√£o de Recursos:** O worker do Airflow tem mem√≥ria e CPU suficientes para a carga de trabalho? Isso envolve ajustar limites no Docker/Kubernetes.
        *   **Escala:** Usar operadores mais eficientes para grandes volumes de dados (ex: operadores Spark, ferramentas espec√≠ficas para cloud).

#### Problema 5: Erro de Conex√£o Externa (`problem_external_connection_dag`)

*   **Descri√ß√£o:** Este DAG tenta conectar a uma API e a um banco de dados usando endere√ßos que *n√£o existem* ou portas erradas. Isso simula falhas comuns de conectividade de rede ou credenciais/configura√ß√µes incorretas.
*   **Categorias de Problema (Slide 13):** Conex√£o Externa.
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_external_connection_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Ambas as tarefas (`test_non_existent_api_connection` e `test_non_existent_db_connection`) falhar√£o.
*   **Diagn√≥stico e Pistas:**
    *   **Logs da tarefa (UI ou `astro dev logs`):** Procure por `requests.exceptions.ConnectionError`, `socket.timeout`, `ConnectionRefusedError` ou `requests.exceptions.Timeout`. As mensagens de erro ser√£o bem expl√≠citas sobre o problema de rede/conex√£o.
    *   A mensagem de erro dir√° o host/IP e a porta que est√£o sendo tentados.
*   **Solu√ß√£o (Discuss√£o):**
    *   Assim como os problemas de recursos, este n√£o √© um erro para ser corrigido no c√≥digo da DAG, a menos que as credenciais estivessem embutidas (o que n√£o √© uma boa pr√°tica!). **O que dever√≠amos investigar para resolver problemas de conex√£o externa?**
        *   Verificar Conectividade de Rede: Pingar o host, verificar firewalls.
        *   Configura√ß√£o de Airflow Connections: As credenciais e o hostname/porta est√£o corretos na `Airflow Connection` (se a tarefa usasse uma)?
        *   Vari√°veis de Ambiente: Se o endpoint/credenciais v√™m de vari√°veis de ambiente, elas est√£o corretas?

## 6. Comandos √öteis do Astro CLI

Aqui est√£o alguns comandos do Astro CLI que ser√£o seus melhores amigos durante o desenvolvimento e o debugging:

*   **`astro dev start`**: Inicia seu ambiente Airflow local.
*   **`astro dev stop`**: Para seu ambiente Airflow local.
*   **`astro dev restart`**: Reinicia todos os componentes do seu ambiente.
*   **`astro dev kill`**: For√ßa a parada e remo√ß√£o de todos os cont√™ineres do seu ambiente local. Use com cautela.
*   **`astro dev logs [--follow]`**: Exibe os logs de todos os servi√ßos do seu ambiente Airflow. Use `--follow` para ver os logs em tempo real.
*   **`astro dev bash`**: Abre um shell Bash dentro do cont√™iner do `scheduler` do Airflow, permitindo que voc√™ execute comandos como se estivesse dentro do ambiente Airflow.
*   **`astro dev run airflow dags test <dag_id> <execution_date>` (Slide 09)**: Simula a execu√ß√£o de uma DAG para uma data espec√≠fica, exibindo os logs e sa√≠das no seu terminal. √ìtimo para testes r√°pidos.
    *   Exemplo: `astro dev run airflow dags test problem_config_and_logic_dag 2023-01-01`
*   **`astro dev run airflow tasks test <dag_id> <task_id> <execution_date>` (Slide 10)**: Simula a execu√ß√£o de uma √∫nica tarefa de uma DAG de forma isolada, sem o scheduler. Essencial para depurar o c√≥digo de uma tarefa espec√≠fica.
    *   Exemplo: `astro dev run airflow tasks test problem_config_and_logic_dag fetch_initial_data 2023-01-01`
*   **`astro dev run airflow dags parse /usr/local/airflow/dags/<nome_do_arquivo_dag>.py` (Slide 10)**: Valida a sintaxe e o processo de importa√ß√£o de uma DAG, identificando erros antes que o scheduler tente carreg√°-la.
    *   Exemplo: `astro dev run airflow dags parse /usr/local/airflow/dags/problem_dag_parsing_error.py`

## 7. Recursos Adicionais

*   **Documenta√ß√£o Oficial do Apache Airflow:** [https://airflow.apache.org/docs/apache-airflow/stable/](https://airflow.apache.org/docs/apache-airflow/stable/)
*   **Documenta√ß√£o Oficial do Astro CLI:** [https://docs.astronomer.io/astro/cli/overview](https://docs.astronomer.io/astro/cli/overview)
*   **Artigos sobre Debugging Airflow:** Procure por "Airflow debugging best practices" ou "troubleshooting Airflow DAGs" em blogs como Astronomer, DataCamp, ou Medium.
*   **Doc que mostra o passo a passo para elaborar um projeto com o Astro CLI:** https://www.astronomer.io/docs/astro/cli/develop-project

## 8. Contribui√ß√£o (Opcional)

Sinta-se √† vontade para sugerir melhorias neste case, adicionar novos cen√°rios de problemas ou aprimorar as explica√ß√µes. Abra uma `Iss
Elaborei um documento no google docs que est√° mais completo e explica em mais detalhes os c√≥digos e o que falei na apresenta√ß√£o. Quem tiver interesse, √© s√≥ pedir!

# PLUS-ULTRA

Vamos l√° pessoal! Vou  tentar colocar alguns t√≥picos aqui aque possam ter relav√¢ncia para voc√™s. Lembrem-se **O material vai ser introdut√≥rio! Programar e desenvolver √© a arte de procurar documenta√ß√µes e tutoriais kkk. Ent√£o por favor, n√£o se limitem ao conte√∫do deste arquivo** Espero ajudar voc√™s! Bora l√°!

**Contexto**: Muitos de voc√™s v√£o precisar orquestrar fluxos de dados que envolvem ferramentas de extra√ß√£o (como Meltano, Embulk) ou de computa√ß√£o (como Databricks CLI para jobs no Spark). A grande sacada do Airflow √© ser o maestro que coordena todas essas ferramentas.
**A Filosofia**: O Airflow n√£o processa dados; ele orquestra quem processa. Para que o Airflow orquestre Meltano, Embulk ou Databricks CLI, essas ferramentas precisam estar dispon√≠veis e acess√≠veis no ambiente onde a task do Airflow est√° rodando (geralmente o Worker do Airflow).
O Astro CLI facilita isso porque ele controla a constru√ß√£o do ambiente Docker do Airflow.

## 1. Preparando Seu Ambiente Astro para Ferramentas Externas
No seu projeto astro (aquele que voc√™ criou com astro dev init), voc√™ tem arquivos-chave para adicionar depend√™ncias:
- ``requirements.txt``: Para depend√™ncias Python. Se Meltano, dbt, ou SDKs (como azure-storage-blob, boto3 para AWS) s√£o pacotes Python, coloque-os aqui.

``` yml
# Exemplo de requirements.txt
apache-airflow-providers-cncf-kubernetes # Se for usar DockerOperator
meltano
dbt-core
dbt-bigquery
databricks-cli
```
- ``packages.txt``: Para depend√™ncias de n√≠vel de sistema operacional (Linux packages - apt-get). Se a ferramenta precisar de algo como openjdk, git, curl, coloque aqui.

```yml
# Exemplo de packages.txt
git
openjdk-17-jdk # Para ferramentas Java-based como Embulk
```

``Dockerfile``: Para customiza√ß√µes mais avan√ßadas (instalar algo de um reposit√≥rio espec√≠fico, compilar algo, etc.). Voc√™ pode estender a imagem base do Airflow aqui.

```yml
# Exemplo de Dockerfile (no seu projeto Astro)
FROM quay.io/astronomer/astro-runtime:x.x.x-pythonx.x # Use a vers√£o do runtime que voc√™ usa
# Instalar Meltano de um fork espec√≠fico (exemplo avan√ßado)
RUN pip install git+https://github.com/your-fork/meltano.git@main
# Instalar Embulk manualmente (se n√£o for via apt)
RUN curl --create-dirs -o /usr/local/bin/embulk -L "https://dl.embulk.org/embulk-latest.jar"
RUN chmod +x /usr/local/bin/embulk
```
- Quando usar qual:
  - requirements.txt: 90% dos casos para Python. Simples e r√°pido.
  - packages.txt: Para bibliotecas C/C++, Java, ou execut√°veis que n√£o s√£o Python.
  - Dockerfile: Se as outras op√ß√µes n√£o forem suficientes, ou para instala√ß√µes muito espec√≠ficas/manuais.

## 2. Exemplo 1: Orquestrando Meltano com Airflow (via BashOperator)

Meltano √© uma ferramenta Python, ent√£o o caminho mais comum √© instal√°-lo via requirements.txt.

### 2.1. Adicione Meltano ao ``requirements.txt``:

```yml
# requirements.txt
meltano
```

### 2.2. **Crie seu Projeto Meltano**: O ideal √© que seu projeto Meltano esteja dentro do seu projeto Astro, por exemplo, na pasta dags/meltano_project/. Isso garante que ele ser√° empacotado junto com suas DAGs.
```
# Estrutura do seu projeto Astro
.
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ sua_dag_meltano.py
‚îÇ   ‚îî‚îÄ‚îÄ meltano_project/  # Seu projeto Meltano aqui
‚îÇ       ‚îú‚îÄ‚îÄ meltano.yml
‚îÇ       ‚îú‚îÄ‚îÄ extract/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ packages.txt
‚îî‚îÄ‚îÄ Dockerfile
```

### 2.4. Crie sua DAG (``sua_dag_meltano.py``): Use o BashOperator para chamar os comandos meltano.

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

with DAG(
    dag_id='meltano_pipeline',
    start_date=days_ago(1),
    schedule_interval=timedelta(days=1),
    catchup=False,
    tags=['meltano', 'etl'],
) as dag:
    # Define o caminho base para o seu projeto Meltano dentro do container do Airflow.
    # Geralmente √© /usr/local/airflow/dags/nome_da_sua_pasta_meltano
    MELTANO_PROJECT_PATH = "/usr/local/airflow/dags/meltano_project/"

    # Task para rodar a extra√ß√£o e carga com Meltano
    run_meltano_elt = BashOperator(
        task_id='extract_load_data',
        # Comando Meltano a ser executado
        bash_command=f"cd {MELTANO_PROJECT_PATH} && meltano elt tap-rest-api target-json --full-refresh",
        # O 'cwd' pode ser usado, mas 'cd' no bash_command √© mais expl√≠cito
    )

    # Task para rodar transforma√ß√µes com dbt (se voc√™ usa Meltano + dbt)
    run_meltano_dbt_transform = BashOperator(
        task_id='transform_data',
        bash_command=f"cd {MELTANO_PROJECT_PATH} && meltano elt tap-rest-api target-json --transform=run",
    )

    run_meltano_elt >> run_meltano_dbt_transform
```

## 3. Teste Localmente com Astro CLI:
- Se for usar o Astro CLI voc√™s v√£o ter que executar antes de tudo o ``astro dev init``
- Suba seu ambiente: astro dev start (ele vai reconstruir a imagem Docker para instalar o Meltano).
- Verifique a instala√ß√£o do Meltano (importante!):
astro dev exec meltano --version
- Se ele retornar a vers√£o do Meltano, est√° tudo certo!
- Dispare a DAG na UI local: Acesse http://localhost:8080, encontre meltano_pipeline e dispare um DAG Run. Monitore os logs da task.

## 4.  Exemplo 2: Orquestrando Embulk com Airflow (via BashOperator)
Embulk √© uma ferramenta baseada em Java. Isso significa que voc√™ precisar√° ter o Java Runtime Environment (JRE) instalado no ambiente do Worker do Airflow.

### 4.1. Adicione Java ao packages.txt:
```yml
# packages.txt
openjdk-17-jdk
```

### 4.2. Baixe o Embulk: O Embulk √© um JAR execut√°vel. Voc√™ pode baix√°-lo e coloc√°-lo na pasta include/ do seu projeto Astro, por exemplo.
```
# Estrutura
.
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ sua_dag_embulk.py
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îî‚îÄ‚îÄ embulk  # Aqui estar√° o JAR do Embulk
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ packages.txt
‚îî‚îÄ‚îÄ Dockerfile
```

### 4.3. Como baixar o Embulk no ``include/``:

```bash
cd include
curl --create-dirs -o embulk -L "https://dl.embulk.org/embulk-latest.jar"
chmod +x embulk # Torna o arquivo execut√°vel. Esse comando √© importante. Se vcs n√£o executarem ele vai dar erro.
cd .. # Volta para a raiz do projeto Astro
```

### 4.4. Crie sua DAG (``sua_dag_embulk.py``): Use o BashOperator para chamar o JAR do Embulk.

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

with DAG(
    dag_id='embulk_pipeline',
    start_date=days_ago(1),
    schedule_interval=timedelta(days=1),
    catchup=False,
    tags=['embulk', 'etl'],
) as dag:
    # Define o caminho para o execut√°vel do Embulk e seus arquivos de configura√ß√£o
    EMBULK_BIN_PATH = "/usr/local/airflow/include/embulk"
    EMBULK_CONFIG_PATH = "/usr/local/airflow/dags/embulk_configs/" # Pasta com seus YMLs de config

    # Task para rodar um job do Embulk
    run_embulk_job = BashOperator(
        task_id='run_data_ingestion',
        bash_command=f"java -jar {EMBULK_BIN_PATH} run {EMBULK_CONFIG_PATH}my_config.yml",
        # Pode ser necess√°rio adicionar -Dembulk.home=... se voc√™ usar plugins complexos
```

### 4.5. Verifique a instala√ß√£o do Java e Embulk:

```bash
astro dev exec java --version
astro dev exec java -jar /usr/local/airflow/include/embulk --version
Dispare a DAG na UI local: Acesse http://localhost:8080, encontre embulk_pipeline e dispare um DAG Run.
```

## 5. Exemplo 3: Databricks CLI e o Poder do ``DockerOperator``
A Databricks CLI √© uma ferramenta Python (databricks-cli), mas a sacada aqui √© introduzir o DockerOperator.

### 5.1. Adicione ``apache-airflow-providers-cncf-kubernetes`` ao ``requirements.txt``: O ``DockerOperator`` faz parte desse provider.

### 5.2. Crie uma Imagem Docker com o Databricks CLI (Opcional, mas recomendado): Se voc√™ n√£o quiser usar uma imagem pronta da Databricks, pode criar a sua.

### 5.3. Exemplo de Dockerfile.databricks (em uma pasta docker_images/ no seu projeto Astro):

```docker
# Imagem base Python, ou algo mais leve
FROM python:3.9-slim-buster

# Instala o Databricks CLI
RUN pip install databricks-cli

# Define um ponto de entrada padr√£o (opcional)
ENTRYPOINT ["databricks"]
```

### 5.5. Construa a imagem:

```docker
docker build -t my-databricks-cli-image -f docker_images/Dockerfile.databricks .
```

### 5.5. Construa a imagem:

```python
from airflow import DAG
from airflow.operators.docker import DockerOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

with DAG(
    dag_id='databricks_cli_pipeline',
    start_date=days_ago(1),
    schedule_interval=timedelta(days=1),
    catchup=False,
    tags=['databricks', 'cli', 'docker'],
) as dag:
    # Configura√ß√µes do DockerOperator
    # imagem: A imagem Docker que ser√° usada para rodar esta task.
    #         Pode ser uma imagem do Docker Hub (ex: python:3.9-slim)
    #         ou uma imagem que voc√™ construiu localmente (my-databricks-cli-image).
    # command: O comando a ser executado dentro do container.
    # environment: Vari√°veis de ambiente a serem passadas para o container.
    #              CRUCIAL para credenciais (DB_HOST, DB_TOKEN)!
    #              Use Connections do Airflow para gerenciar isso de forma segura!

    # Exemplo com Databricks CLI: Executar um notebook
    run_databricks_notebook = DockerOperator(
        task_id='run_my_databricks_notebook',
        image='my-databricks-cli-image', # Ou uma imagem oficial que contenha o CLI
        command="databricks jobs run-now --job-id 12345 --host $DATABRICKS_HOST --token $DATABRICKS_TOKEN",
        environment={
            # Estes devem vir de Connections do Airflow para produ√ß√£o!
            # Para local, pode ser via vari√°veis de ambiente no Dockerfile ou .env do Astro CLI
            "DATABRICKS_HOST": "{{ conn.databricks_default.host }}",
            "DATABRICKS_TOKEN": "{{ conn.databricks_default.password }}"
        },
        network_mode="bridge", # Para que o container possa acessar a rede
        # mount_tmp_dir: True # Para permitir que o container use /tmp
    )

    # Exemplo com Meltano usando DockerOperator (se voc√™ tivesse uma imagem Meltano)
    # run_meltano_in_docker = DockerOperator(
    #     task_id='run_meltano_in_isolated_container',
    #     image='my-meltano-image:latest', # Imagem Docker com Meltano pr√©-instalado
    #     command='meltano elt tap-rest-api target-json',
    #     # mounts=... # Para montar o volume do projeto Meltano se ele n√£o estiver na imagem
    # )
```

### 5.6. Configura√ß√£o de Credenciais:

- **Crucial**: Nunca coloque credenciais diretamente no c√≥digo da DAG! Use as **Connections do Airflow**.
- Para o ``DockerOperator``, voc√™ pode puxar as credenciais das Connections do Airflow e pass√°-las como vari√°veis de ambiente para o container.
- Localmente com Astro CLI:
  - Voc√™ pode configurar essas Connections na UI local (Admin > Connections).
  - Ou, se estiver usando a funcionalidade de .env do Astro CLI, pode definir vari√°veis de ambiente que o Astro CLI passar√° para o Airflow.
  - ``DATABRICKS_HOST`` e ``DATABRICKS_TOKEN`` precisam estar acess√≠veis para o container do DockerOperator.

### 5.6. Teste Localmento com Astro CLI executando ``astro dev start``

### 5.7. Verifique se o docker est√° funcionando dentro do worker (importante para DockerOperator):

```bash
astro dev exec docker ps
# Voc√™ deve ver os containers do seu ambiente Airflow. Isso confirma que o Docker est√° acess√≠vel para o Worker.
```

### 5.8. Dispare a DAG na UI local: Acesse http://localhost:8080, encontre databricks_cli_pipeline e dispare um DAG Run.

## Conclus√£o
Como voc√™s puderam ver, o Astro CLI n√£o √© apenas uma ferramenta para ligar e desligar o Airflow. Ele √© o seu portal para um desenvolvimento de dados robusto e orquestrado. Ao entender como ele gerencia o ambiente Docker e como voc√™ pode integrar suas ferramentas favoritas (Meltano, Embulk, Databricks CLI, etc.) via ``requirements.txt``, ``packages.txt``, ``Dockerfile`` e, especialmente, o ``DockerOperator``, voc√™s estar√£o prontos para construir pipelines de dados de n√≠vel profissional.
Continuem explorando e testando! O conhecimento vem da pr√°tica.


# üö® AVISO AOS NAVEGANTES DE DADOS üö®

Queridos Lighthouses e aspirantes a domadores de pipelines,

N√£o vai adiantar fazer CTRL+C e CTRL+V neste tutorial como se fosse um docker pull da sabedoria! Dei apenas um SELECT * FROM conhecimento LIMIT 10 nas etapas essenciais, mas isso n√£o vai te salvar de ter que fazer um JOIN com as documenta√ß√µes oficiais!

Como j√° comentei em algum commit perdido deste README (talvez em uma branch que nem existe mais üòÇ), desenvolver √© basicamente a arte de ler documenta√ß√µes enquanto chora silenciosamente para o seu caf√©. √â como configurar um DAG no Airflow: parece simples na teoria, mas na pr√°tica voc√™ acaba com 37 abas abertas no navegador e questionando suas escolhas de vida. Faz parte do processo, mas, acreditem!

Lembrem-se:

- O Airflow n√£o perdoa quem n√£o l√™ a documenta√ß√£o (ele vai falhar √†s 3h da manh√£ de um domingo)
- O Docker vai quebrar de formas que voc√™ nem imaginava poss√≠veis
- O Meltano vai te fazer questionar por que n√£o escolheu ser fazendeiro
- O Databricks vai te cobrar por recursos que voc√™ nem sabia que estava usando
- E o Embulk... bem, se voc√™ conseguir fazer o Embulk funcionar de primeira, por favor escreva um livro e me d√° de presente kkk

Espero, de cora√ß√£o, ter ajudado um pouco voc√™s nessa jornada.

Fico √† disposi√ß√£o para mais dicas ou para chorar junto sobre YAMLs mal indentados!