# airflow-lighthouse-aula-pratica-debugg
# üõ†Ô∏è Astro CLI + Airflow: Debugging e Solu√ß√£o de Problemas em Orquestra√ß√£o

## 1. Vis√£o Geral

Bem-vindos ao reposit√≥rio de suporte √† aula pr√°tica de "Lidando com problemas de Orquestra√ß√£o | Airflow, debugging, logs"! Este projeto foi cuidadosamente elaborado para simular **cinco cen√°rios comuns de falhas** em pipelines de dados orquestrados pelo Apache Airflow.

Aqui, voc√™ ter√° a oportunidade de aplicar os conceitos te√≥ricos aprendidos na aula, utilizando o **Astro CLI** para agilizar o desenvolvimento e depura√ß√£o local, e a **Airflow UI** para monitoramento e an√°lise detalhada. Nosso objetivo √© transformar voc√™ em um verdadeiro "detetive" de dados, capaz de navegar pela complexidade e garantir a resili√™ncia dos seus pipelines, mesmo **sem depender exclusivamente da interface gr√°fica**.

## 2. Pr√©-requisitos - Preparando seu Ambiente

Para que voc√™ possa executar este projeto e aproveitar a experi√™ncia pr√°tica, certifique-se de ter os seguintes softwares e ferramentas instalados e configurados em sua m√°quina. **√â crucial seguir estas etapas para garantir que o Astro CLI funcione corretamente.**

1.  **[VS Code](https://code.visualstudio.com/):** Nosso ambiente de desenvolvimento integrado (IDE) preferido. Ele oferece excelentes recursos para Python e Docker. Instale-o se ainda n√£o tiver.
2.  **[Docker Desktop](https://www.docker.com/products/docker-desktop/):** O Astro CLI utiliza Docker para criar e gerenciar seu ambiente Airflow local. **Certifique-se de que o Docker Desktop esteja em execu√ß√£o** antes de iniciar o ambiente Astro. Fa√ßa o download e a instala√ß√£o para o seu sistema operacional.
3.  **[Astro CLI](https://docs.astronomer.io/astro/cli/install-cli):** A ferramenta de linha de comando essencial para interagir com o Airflow, tanto localmente quanto com o Astronomer Cloud.

    ### Instala√ß√£o do Astro CLI (Escolha uma op√ß√£o):

    *   **macOS (Homebrew):**
        ```bash
        brew install astro
        ```
    *   **Linux (apt):**
        ```bash
        curl -sL 'https://raw.githubusercontent.com/astronomer/astro-cli/main/install.sh' | sudo bash -s -- -b /usr/local/bin
        ```
    *   **Windows (Chocolatey ou WSL):** A forma mais recomendada para Windows √© usar o [WSL (Windows Subsystem for Linux)](https://learn.microsoft.com/pt-br/windows/wsl/) e instalar o Astro CLI dentro dele, seguindo as instru√ß√µes do Linux. Alternativamente, voc√™ pode usar o Chocolatey.
        ```powershell
        # No PowerShell (como Administrador)
        choco install astro-cli
        ```
        (Verifique a documenta√ß√£o oficial para a instala√ß√£o mais atualizada para Windows). 

    ### Verifica√ß√£o da Instala√ß√£o do Astro CLI:

    Ap√≥s a instala√ß√£o, abra seu terminal (ou o terminal integrado do VS Code) e execute:
    ```bash
    astro version
    ```
    Voc√™ dever√° ver a vers√£o do Astro CLI instalada. Se voc√™ receber um erro, revise as etapas de instala√ß√£o.

## 3. Configura√ß√£o e Inicializa√ß√£o do Ambiente

Siga estes passos para configurar e iniciar seu ambiente Airflow local. **Leia com aten√ß√£o para entender o fluxo de trabalho local com o Astro CLI.**

1.  **Clone o Reposit√≥rio e crie um arquivo de requirements.txt:**
    Abra seu terminal e execute:
    ```bash
    git clone https://github.com/LucasJFaust/airflow-lighthouse-aula-pratica-debugg # Substitua pela URL real do seu reposit√≥rio
    cd seu-repositorio-de-aula # Navegue at√© a pasta do projeto
    ```
     **Verifique e prepare o `requirements.txt`:**
    O Astro CLI utiliza o arquivo `requirements.txt` (localizado na raiz do seu projeto) para instalar as depend√™ncias Python necess√°rias dentro do ambiente Airflow. **Certifique-se de que este arquivo existe e contenha todas as bibliotecas que suas DAGs ir√£o utilizar (como `requests`, `apache-airflow` na vers√£o desejada, etc.) ANTES de iniciar o ambiente.**

    Exemplo de `requirements.txt` para este projeto:
    ```
    requests
    ```
    *   **Importante:** Se voc√™ modificar o `requirements.txt` ap√≥s o `astro dev start` inicial, ser√° necess√°rio executar `astro dev restart` (ou `astro dev kill` e `astro dev start`) para que as novas depend√™ncias sejam instaladas nos cont√™ineres do Airflow.
    No terminal execute:
    ```bash
    touch requirements.txt
    ```


2.  **Inicie o Ambiente Airflow Local com Astro CLI:**
     Este comando cria a estrutura de projeto que o Astro CLI espera (`.astro/` folder, `Dockerfile` e `packages.txt`).
    ```bash
    astro dev init
    ```
    *   Se for perguntado sobre sobrescrever arquivos como `Dockerfile` ou `packages.txt`, pode aceitar as op√ß√µes padr√£o ou pular se j√° tiverem customiza√ß√µes que voc√™ queira manter (neste caso, para a aula, os padr√µes s√£o suficientes).
    *   **Opcional:** Se voc√™ tem customiza√ß√µes em um `Dockerfile` ou `packages.txt` que n√£o foram criados pelo `astro dev init`, voc√™ pode mov√™-los para dentro da pasta `.astro/` ap√≥s a inicializa√ß√£o. Para este laborat√≥rio, o `astro dev init` j√° cria o b√°sico necess√°rio.
    Dentro da pasta do projeto (`seu-repositorio-de-aula`), execute o comando para iniciar o ambiente Airflow local. **Este √© o comando chave para come√ßar a trabalhar. Verifique que est√° executando ele no diret√≥rio correto.**
    ```bash
    astro dev start
    ```
    *   Este comando ir√°:
        *   Ler o arquivo `requirements.txt` e instalar as depend√™ncias Python no ambiente Airflow.
        *   Baixar as imagens Docker necess√°rias (Airflow Scheduler, Webserver, PostgreSQL, Redis).
        *   Construir os cont√™ineres e inici√°-los, configurando as redes e volumes necess√°rios.
        *   Sincronizar seus arquivos de DAGs (na pasta `dags/`) com o cont√™iner do Airflow.
    *   Este processo pode levar **v√°rios minutos na primeira vez** (especialmente o download das imagens). Tenha paci√™ncia.

    ### Solu√ß√£o de Problemas Comuns `astro dev start`:

    *   **Docker Desktop n√£o iniciado:** Verifique se o Docker Desktop est√° rodando. O `astro dev start` *depende* dele.
    *   **Porta 8080 em uso:** Se voc√™ tiver outro servi√ßo usando a porta `8080`, o Astro CLI pode falhar. Voc√™ pode parar o outro servi√ßo ou, para ambientes mais avan√ßados, configurar o `docker-compose.yaml` gerado pelo Astro CLI em `.astro/` para usar outra porta.
    *   **Erros de `requirements.txt`:** Se houver erros na instala√ß√£o de pacotes Python, verifique a sintaxe do seu `requirements.txt`.

3.  **Acesse a UI do Airflow:**
    Ap√≥s o `astro dev start` concluir, o terminal exibir√° a URL da interface do usu√°rio do Airflow. Geralmente, √©:
    [http://localhost:8080/](http://localhost:8080/) 
    Abra essa URL em seu navegador. As credenciais padr√£o s√£o `admin`/`admin`.

## 4. Estrutura do Projeto

Entender a estrutura do projeto √© crucial para a navega√ß√£o e o debugging:
seu-repositorio-de-aula/ ‚îú‚îÄ‚îÄ dags/ # Cont√©m os arquivos Python das DAGs ‚îÇ ‚îú‚îÄ‚îÄ problem_config_and_logic_dag.py # Problema 1: Vari√°vel e L√≥gica ‚îÇ ‚îú‚îÄ‚îÄ problem_stuck_sensor_dag.py # Problema 2: Sensor que trava ‚îÇ ‚îú‚îÄ‚îÄ problem_dag_parsing_error.py # Problema 3: Erro de Parsing/Sintaxe (DAG n√£o aparece!) ‚îÇ ‚îú‚îÄ‚îÄ problem_resource_intensive_dag.py # Problema 4: Consumo de Recursos (OOMKilled/Lento) ‚îÇ ‚îî‚îÄ‚îÄ problem_external_connection_dag.py # Problema 5: Erro de Conex√£o Externa ‚îú‚îÄ‚îÄ data/ # Cont√©m arquivos de dados de exemplo utilizados pelas DAGs ‚îÇ ‚îî‚îÄ‚îÄ initial_data.txt ‚îú‚îÄ‚îÄ .astro/ # Diret√≥rio oculto gerado pelo Astro CLI com configura√ß√µes ‚îú‚îÄ‚îÄ .env # Arquivo de vari√°veis de ambiente (se usado) ‚îú‚îÄ‚îÄ requirements.txt # Lista de pacotes Python para o ambiente Airflow ‚îú‚îÄ‚îÄ docker-compose.yaml # Arquivo Docker Compose gerado pelo Astro CLI ‚îî‚îÄ‚îÄ README.md # Este arquivo!


## 5. O Case T√©cnico - Cen√°rios de Problemas (e como diagnostic√°-los!)

Este projeto cont√©m **cinco DAGs intencionalmente problem√°ticas**, cada uma demonstrando um tipo diferente de falha comum em pipelines de dados Airflow, conforme discutido no **Slide 13: Fontes de Problemas**.

Para cada problema, voc√™ dever√° usar as ferramentas visuais da Airflow UI e os poderosos comandos do Astro CLI para identificar e diagnosticar a causa raiz.

### Guia Geral de Debugging e An√°lise de Logs (Sua Caixa Preta!)

Antes de mergulhar nos problemas espec√≠ficos, familiarize-se com a abordagem geral de depura√ß√£o, que integra os conceitos dos **Slides 05, 06, 11 e 12** da apresenta√ß√£o:

1.  **Identifica√ß√£o Visual (Airflow UI - Grid View / Graph View):**
    *   V√° para a `Grid View` do DAG problem√°tico. Observe o status geral.
    *   **Pergunte-se (Slide 05 - Grid View):** "Qual tarefa est√° em vermelho (falha) ou em um estado inesperado (`up_for_retry`, `running` indefinidamente)? Quais s√£o as cores das outras tarefas? H√° algum padr√£o de falha?"
    *   Navegue para a `Graph View` do DAG.
    *   **Pergunte-se (Slide 06 - Graph View):** "Qual √© a sequ√™ncia de execu√ß√£o? Qual tarefa falhou e quais tarefas s√£o `downstream` dela? Elas foram `skipped`? Isso faz sentido com as depend√™ncias?"

2.  **An√°lise de Logs (Airflow UI - Task Instance Logs / Astro CLI Logs):**
    *   **Primeira Leitura (UI):** Na `Grid View` ou `Graph View`, clique na tarefa falha (ou na que est√° travada) e selecione "View Log" ou "Logs".
    *   **Pergunte-se (Slide 11 - Anatomia dos Logs):**
        *   "Qual √© o `Timestamp` do erro? Houve algum evento anterior relevante?"
        *   "Qual √© o `Level` da mensagem? Estou vendo `ERROR` ou `CRITICAL`?"
        *   "Qual a `Message` do erro? H√° alguma mensagem `print()` minha que pode dar uma pista?"
        *   "H√° um `StackTrace`? Se sim, lembre-se: **leia de baixo para cima**! Qual o `Exception Type` e onde est√° o n√∫mero da linha no c√≥digo da minha DAG?"
    *   **Leitura Detalhada (Astro CLI) - SEMPRE QUE POSS√çVEL, USE ESTES COMANDOS!**
        Abra um novo terminal no VS Code (sem parar o `astro dev start`).
        *   Para ver logs de uma tarefa espec√≠fica diretamente no terminal (mais r√°pido e f√°cil para copiar):
            ```bash
            astro dev logs --dag-id <dag_id> --task-id <task_id> --follow
            # Exemplo: astro dev logs --dag-id problem_config_and_logic_dag --task-id process_data_with_config_and_logic_error --follow
            ```
        *   Para seguir os logs de todos os componentes do Airflow (√∫til para `Scheduler` e `Webserver` logs):
            ```bash
            astro dev logs --follow
            ```
        *   **Pergunte-se (Slide 12 - Estrat√©gias de Busca):** "Com quais `Keywords` posso procurar? `ERROR`, `Exception`, `Failed`, `Traceback`? Posso filtrar por `task_id` ou `Timestamp`?"

3.  **Diagn√≥stico e Racioc√≠nio L√≥gico (Aplicando o Slide 13 - Fontes de Problemas):**
    *   Com base nos logs, qual √© a **causa raiz** do problema?
    *   **Pergunte-se:** "Qual categoria de problema (do Slide 13) se encaixa melhor aqui? Isso me ajuda a pensar na solu√ß√£o?"
    *   **Pergunte-se:** "Como eu poderia simular esse erro rapidamente localmente para testar uma poss√≠vel corre√ß√£o, antes de mudar o DAG completo, **sem precisar da UI do Airflow**?" (Pense nos comandos `astro dev run airflow tasks test` ou `astro dev run airflow dags parse` - **Slide 10**).

---

### Detalhes de Cada Problema e Passos para Reprodu√ß√£o

#### Problema 1: Vari√°vel de Configura√ß√£o Ausente e Erro de L√≥gica (`problem_config_and_logic_dag`)

*   **Descri√ß√£o:** Este DAG falha porque espera uma `Airflow Variable` (`processing_chunk_size`) que n√£o est√° definida na UI do Airflow. Al√©m disso, se a vari√°vel fosse definida, h√° um erro l√≥gico que pode ocorrer em um caso de borda.
*   **Categorias de Problema (Slide 13):** Permiss√µes/Vari√°veis (principal), L√≥gica da Task (secund√°rio).
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_config_and_logic_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Observe a falha na `Grid View`.
*   **Diagn√≥stico e Pistas:**
    *   A tarefa `process_data_with_config_and_logic_error` falhar√°.
    *   Os logs (UI ou `astro dev logs`) mostrar√£o um `KeyError` ou `ValueError` relacionado √† `Variable.get("processing_chunk_size")`.
*   **Solu√ß√£o:**
    1.  **Corrija a Vari√°vel:** Na Airflow UI, v√° em `Admin` -> `Variables`. Crie uma nova vari√°vel com **Key:** `processing_chunk_size` e **Value:** `10` (ou qualquer n√∫mero inteiro).
    2.  Dispare o DAG novamente. Observe que ele passar√° pela primeira falha.
    3.  *(Opcional/Discuss√£o em aula):* Se o `IndexError` surgir (dependendo da manipula√ß√£o de `initial_data.txt`), mostre como o `astro dev run airflow tasks test` para a fun√ß√£o `_process_data_with_config_and_logic_error` poderia ter ajudado a isolar o erro de l√≥gica.

#### Problema 2: Sensor Travado (`problem_stuck_sensor_dag`)

*   **Descri√ß√£o:** Este DAG tem um `FileSensor` que aguarda a cria√ß√£o de um arquivo espec√≠fico (`/tmp/data_notification_file.txt`). No entanto, a tarefa anterior que deveria criar este arquivo (`_generate_data_but_fail_to_create_notification_file`) *intencionalmente n√£o o faz*, fazendo com que o sensor fique travado at√© atingir seu `timeout`.
*   **Categorias de Problema (Slide 13):** L√≥gica da Task (a tarefa anterior falha em sua l√≥gica de notifica√ß√£o), Conex√£o Externa (do ponto de vista do sensor, o evento externo n√£o ocorreu).
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_stuck_sensor_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Observe que a tarefa `wait_for_data_notification` permanecer√° em estado `running` (ou `up_for_retry`) por um tempo, eventualmente falhando por `timeout`.
*   **Diagn√≥stico e Pistas:**
    *   Os logs da tarefa `wait_for_data_notification` mostrar√£o repeti√ß√µes de "Poking for file..." e, eventualmente, um `AirflowSensorTimeout`.
    *   Os logs da tarefa `generate_data_but_fail_to_create_notification_file` (a `upstream`) s√£o cruciais: eles indicar√£o que o arquivo *n√£o* foi criado intencionalmente. Use `astro dev logs` para v√™-los em detalhe.
*   **Solu√ß√£o:**
    1.  **Edite o DAG:** No VS Code, abra `dags/problem_stuck_sensor_dag.py`.
    2.  Na fun√ß√£o `_generate_data_but_fail_to_create_notification_file`, **descomente as linhas** que criam o arquivo `/tmp/data_notification_file.txt`.
    3.  Salve o arquivo. O Airflow recarregar√° a DAG.
    4.  Dispare o DAG novamente na UI. O sensor dever√° passar rapidamente.

#### Problema 3: Erro de Parsing/Sintaxe (`problem_dag_parsing_error`)

*   **Descri√ß√£o:** Este arquivo de DAG (`problem_dag_parsing_error.py`) cont√©m um erro de sintaxe Python intencional. Isso impedir√° que o `Airflow Scheduler` consiga carreg√°-lo, resultando na DAG **n√£o aparecendo na UI** ou gerando um `Dag Import Error` no log do Scheduler.
*   **Categorias de Problema (Slide 13):** Parsing da DAG.
*   **Passos para Reproduzir:**
    1.  **Inicialmente, esta DAG N√ÉO APARECER√Å na UI do Airflow.** Este √© o primeiro sinal.
    2.  Se voc√™ tentar corrigir, mas o erro persistir, o Scheduler pode reclamar.
*   **Diagn√≥stico e Pistas (SEM A UI!):**
    *   **Primeira pista:** A DAG simplesmente n√£o est√° na lista de DAGs da Airflow UI.
    *   **Astro CLI para diagnosticar parsing (Slide 10):**
        Abra um terminal e execute:
        ```bash
        astro dev run airflow dags parse /usr/local/airflow/dags/problem_dag_parsing_error.py
        ```
        *Este comando ir√° simular o processo de parsing do Airflow e reportar o erro de sintaxe diretamente no seu terminal, indicando a linha exata!*
    *   Verifique os logs do Scheduler via `astro dev logs --follow`. Voc√™ ver√° mensagens de `DagFileProcessor` falhando ao carregar o arquivo.
*   **Solu√ß√£o:**
    1.  **Edite o DAG:** No VS Code, abra `dags/problem_dag_parsing_error.py`.
    2.  **Corrija o erro de sintaxe:** Por exemplo, adicione o par√™ntese `)` que falta na linha do `print()`.
    3.  Salve o arquivo. O Scheduler detectar√° a mudan√ßa e tentar√° recarregar.
    4.  Verifique a Airflow UI; a DAG `problem_dag_parsing_error` agora dever√° aparecer.

#### Problema 4: Uso Intenso de Recursos (`problem_resource_intensive_dag`)

*   **Descri√ß√£o:** A tarefa `consume_memory_and_cpu_task` tenta alocar uma grande quantidade de mem√≥ria e/ou executa um loop pesado. Dependendo da configura√ß√£o de recursos do seu ambiente Docker, isso pode levar a:
    *   Uma falha `OOMKilled` (Out Of Memory Killed), onde o sistema operacional encerra a tarefa.
    *   Uma execu√ß√£o extremamente lenta que eventualmente atinge um timeout do Airflow, ou apenas demora muito.
*   **Categorias de Problema (Slide 13):** Recursos.
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_resource_intensive_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Observe o status da tarefa. Ela pode ficar `running` por muito tempo e, em seguida, falhar.
*   **Diagn√≥stico e Pistas:**
    *   **Logs da tarefa (UI ou `astro dev logs`):** Procure por mensagens como `Killed`, `SIGKILL`, ou informa√ß√µes sobre uso de mem√≥ria excessivo. Muitas vezes, n√£o h√° um `Traceback` Python claro, apenas uma indica√ß√£o de que o processo foi encerrado pelo sistema.
    *   **Observa√ß√£o de recursos do Docker Desktop:** Monitore o uso de mem√≥ria/CPU do Docker Desktop enquanto a tarefa roda.
*   **Solu√ß√£o (Discuss√£o):**
    *   Este problema n√£o tem uma "corre√ß√£o de c√≥digo" simples, mas sim uma discuss√£o sobre:
        *   **Otimiza√ß√£o do C√≥digo:** A tarefa est√° processando dados de forma ineficiente? H√° maneiras de reduzir o consumo de mem√≥ria (ex: processar em chunks)?
        *   **Configura√ß√£o de Recursos:** O worker do Airflow tem mem√≥ria e CPU suficientes para a carga de trabalho? Isso envolve ajustar limites no Docker/Kubernetes.
        *   **Escala:** Usar operadores mais eficientes para grandes volumes de dados (ex: operadores Spark, ferramentas espec√≠ficas para cloud).

#### Problema 5: Erro de Conex√£o Externa (`problem_external_connection_dag`)

*   **Descri√ß√£o:** Este DAG tenta conectar a uma API e a um banco de dados usando endere√ßos que *n√£o existem* ou portas erradas. Isso simula falhas comuns de conectividade de rede ou credenciais/configura√ß√µes incorretas.
*   **Categorias de Problema (Slide 13):** Conex√£o Externa.
*   **Passos para Reproduzir:**
    1.  Na Airflow UI, ative o DAG `problem_external_connection_dag`.
    2.  Clique em `Trigger DAG`.
    3.  Ambas as tarefas (`test_non_existent_api_connection` e `test_non_existent_db_connection`) falhar√£o.
*   **Diagn√≥stico e Pistas:**
    *   **Logs da tarefa (UI ou `astro dev logs`):** Procure por `requests.exceptions.ConnectionError`, `socket.timeout`, `ConnectionRefusedError` ou `requests.exceptions.Timeout`. As mensagens de erro ser√£o bem expl√≠citas sobre o problema de rede/conex√£o.
    *   A mensagem de erro dir√° o host/IP e a porta que est√£o sendo tentados.
*   **Solu√ß√£o (Discuss√£o):**
    *   Assim como os problemas de recursos, este n√£o √© um erro para ser corrigido no c√≥digo da DAG, a menos que as credenciais estivessem embutidas (o que n√£o √© uma boa pr√°tica!). **O que dever√≠amos investigar para resolver problemas de conex√£o externa?**
        *   Verificar Conectividade de Rede: Pingar o host, verificar firewalls.
        *   Configura√ß√£o de Airflow Connections: As credenciais e o hostname/porta est√£o corretos na `Airflow Connection` (se a tarefa usasse uma)?
        *   Vari√°veis de Ambiente: Se o endpoint/credenciais v√™m de vari√°veis de ambiente, elas est√£o corretas?

## 6. Comandos √öteis do Astro CLI

Aqui est√£o alguns comandos do Astro CLI que ser√£o seus melhores amigos durante o desenvolvimento e o debugging:

*   **`astro dev start`**: Inicia seu ambiente Airflow local.
*   **`astro dev stop`**: Para seu ambiente Airflow local.
*   **`astro dev restart`**: Reinicia todos os componentes do seu ambiente.
*   **`astro dev kill`**: For√ßa a parada e remo√ß√£o de todos os cont√™ineres do seu ambiente local. Use com cautela.
*   **`astro dev logs [--follow]`**: Exibe os logs de todos os servi√ßos do seu ambiente Airflow. Use `--follow` para ver os logs em tempo real.
*   **`astro dev bash`**: Abre um shell Bash dentro do cont√™iner do `scheduler` do Airflow, permitindo que voc√™ execute comandos como se estivesse dentro do ambiente Airflow.
*   **`astro dev run airflow dags test <dag_id> <execution_date>` (Slide 09)**: Simula a execu√ß√£o de uma DAG para uma data espec√≠fica, exibindo os logs e sa√≠das no seu terminal. √ìtimo para testes r√°pidos.
    *   Exemplo: `astro dev run airflow dags test problem_config_and_logic_dag 2023-01-01`
*   **`astro dev run airflow tasks test <dag_id> <task_id> <execution_date>` (Slide 10)**: Simula a execu√ß√£o de uma √∫nica tarefa de uma DAG de forma isolada, sem o scheduler. Essencial para depurar o c√≥digo de uma tarefa espec√≠fica.
    *   Exemplo: `astro dev run airflow tasks test problem_config_and_logic_dag fetch_initial_data 2023-01-01`
*   **`astro dev run airflow dags parse /usr/local/airflow/dags/<nome_do_arquivo_dag>.py` (Slide 10)**: Valida a sintaxe e o processo de importa√ß√£o de uma DAG, identificando erros antes que o scheduler tente carreg√°-la.
    *   Exemplo: `astro dev run airflow dags parse /usr/local/airflow/dags/problem_dag_parsing_error.py`

## 7. Recursos Adicionais

*   **Documenta√ß√£o Oficial do Apache Airflow:** [https://airflow.apache.org/docs/apache-airflow/stable/](https://airflow.apache.org/docs/apache-airflow/stable/) 
*   **Documenta√ß√£o Oficial do Astro CLI:** [https://docs.astronomer.io/astro/cli/overview](https://docs.astronomer.io/astro/cli/overview) 
*   **Artigos sobre Debugging Airflow:** Procure por "Airflow debugging best practices" ou "troubleshooting Airflow DAGs" em blogs como Astronomer, DataCamp, ou Medium.

## 8. Contribui√ß√£o (Opcional)

Sinta-se √† vontade para sugerir melhorias neste case, adicionar novos cen√°rios de problemas ou aprimorar as explica√ß√µes. Abra uma `Iss